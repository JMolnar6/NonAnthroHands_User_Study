{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Anthropomorphic Hand Data Loading and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up:\n",
    "# %matplotlib widget\n",
    "# %matplotlib inline\n",
    "# %matplotlib ipympl\n",
    "# %matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting Packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "savefig_options = dict(format=\"png\", dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# import ipywidgets as widget\n",
    "\n",
    "# Computation packages\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.signal import find_peaks\n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nah.loader import load_raw_csv_data, load_npzs\n",
    "from nah.utils import norm_data, full_align, full_joint_align, clean_rot_data, segment_by_demo,sum_of_squares\n",
    "\n",
    "from nah.plot import plot_norm, plot_pos, plot_rot, plot_raw_data, plot_raw_data_subsampled,view_participant_robot_gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Functions are all defined. Let's grab some data sets and get them ordered\n",
    "\n",
    "# robot_name = \"Reachy\"\n",
    "# end_eff_name = \"r_wrist2hand\"\n",
    "\n",
    "# robot_name = \"j2s6s300\"\n",
    "# end_eff_name = \"j2s6s300_end_effector\"\n",
    "\n",
    "# for gesture_num in range(3,4):\n",
    "# #     print(gesture_num)\n",
    "#     for demo_num in range(1,6):\n",
    "#         print(gesture_num, demo_num)\n",
    "#         end_eff_data, hand_data, camera_data, joint_data = load_raw_csv_dataobot_name,end_eff_name, PID, gesture_num, demo_num)\n",
    "#         warp_path = norm_data(gesture_num, demo_num, end_eff_data, hand_data)\n",
    "#         time_URDF_aligned, time_hand_aligned, end_eff_pos_aligned, end_eff_rot_aligned, hand_pos_aligned, hand_rot_aligned = \\\n",
    "#             full_align(warp_path, end_eff_data, hand_data)\n",
    "#         hand_rot_aligned = clean_rot_data(gesture_num, demo_num, hand_rot_aligned)\n",
    "#         hand_rot_aligned = clean_rot_data(gesture_num, demo_num, hand_rot_aligned) #Seems to work better if you do it twice for some reason\n",
    "#         plot_pos(gesture_num, demo_num, warp_path, end_eff_pos_aligned, hand_pos_aligned)\n",
    "#         plot_rot(gesture_num, demo_num, warp_path, end_eff_rot_aligned, hand_rot_aligned)\n",
    "        \n",
    "#         np.savez('data_PID'+str(PID)+\"_\"+str(robot_name)+\"_gesture_\"+str(gesture_num)+'_'+str(demo_num),time_URDF_aligned=time_URDF_aligned, time_hand_aligned=time_hand_aligned,\\\n",
    "#                 end_eff_pos_aligned=end_eff_pos_aligned, end_eff_rot_aligned=end_eff_rot_aligned, \\\n",
    "#                 hand_pos_aligned=hand_pos_aligned, hand_rot_aligned=hand_rot_aligned, \\\n",
    "#                 camera_data = camera_data, \\\n",
    "#                 gesture_num=gesture_num, demo_num=demo_num, warp_path=warp_path, end_eff_data=end_eff_data, hand_data=hand_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 1 1\n",
      "14 1 2\n",
      "14 1 3\n",
      "14 1 4\n",
      "14 1 5\n",
      "14 2 1\n",
      "14 2 2\n",
      "14 2 3\n",
      "14 2 4\n",
      "14 2 5\n",
      "14 3 1\n",
      "14 3 2\n",
      "14 3 3\n",
      "14 3 4\n",
      "14 3 5\n",
      "14 4 1\n",
      "14 4 2\n",
      "14 4 3\n",
      "14 4 4\n",
      "14 4 5\n",
      "14 5 1\n",
      "14 5 2\n",
      "14 5 3\n",
      "14 5 4\n",
      "14 5 5\n",
      "14 6 1\n",
      "14 6 2\n",
      "14 6 3\n",
      "14 6 4\n",
      "14 6 5\n",
      "14 7 1\n",
      "14 7 2\n",
      "14 7 3\n",
      "14 7 4\n",
      "14 7 5\n",
      "14 8 1\n",
      "14 8 2\n",
      "14 8 3\n",
      "14 8 4\n",
      "14 8 5\n",
      "14 9 1\n",
      "14 9 2\n",
      "14 9 3\n",
      "14 9 4\n",
      "14 9 5\n",
      "14 10 1\n",
      "14 10 2\n",
      "14 10 3\n",
      "14 10 4\n",
      "14 10 5\n",
      "14 11 1\n",
      "14 11 2\n",
      "14 11 3\n",
      "14 11 4\n",
      "14 11 5\n",
      "14 12 1\n",
      "14 12 2\n",
      "14 12 3\n",
      "14 12 4\n",
      "14 12 5\n",
      "14 13 1\n",
      "14 13 2\n",
      "14 13 3\n",
      "14 13 4\n",
      "14 13 5\n",
      "14 14 1\n",
      "14 14 2\n",
      "14 14 3\n",
      "14 14 4\n",
      "14 14 5\n",
      "14 15 1\n",
      "14 15 2\n",
      "14 15 3\n",
      "14 15 4\n",
      "14 15 5\n",
      "C:\\Users\\jmoln\\Documents\\Projects\\NonAnthroHands_User_Study\\data\\PID14\\Reachy_PID14_r_wrist2hand_Motion_gesture_15_5.csv not found, loading alternate data from followup\n",
      "Import data failed for PID 14, gesture 15, demo_num 5\n",
      "15 1 1\n",
      "15 1 2\n",
      "15 1 3\n",
      "15 1 4\n",
      "15 1 5\n",
      "15 2 1\n",
      "15 2 2\n",
      "15 2 3\n",
      "15 2 4\n",
      "15 2 5\n",
      "15 3 1\n",
      "15 3 2\n",
      "15 3 3\n",
      "15 3 4\n",
      "15 3 5\n",
      "15 4 1\n",
      "15 4 2\n",
      "15 4 3\n",
      "15 4 4\n",
      "15 4 5\n",
      "15 5 1\n",
      "15 5 2\n",
      "15 5 3\n",
      "15 5 4\n",
      "15 5 5\n",
      "15 6 1\n",
      "15 6 2\n",
      "15 6 3\n",
      "15 6 4\n",
      "15 6 5\n",
      "15 7 1\n",
      "15 7 2\n",
      "15 7 3\n",
      "15 7 4\n",
      "15 7 5\n",
      "15 8 1\n",
      "15 8 2\n",
      "15 8 3\n",
      "15 8 4\n",
      "15 8 5\n",
      "15 9 1\n",
      "15 9 2\n",
      "15 9 3\n",
      "15 9 4\n",
      "15 9 5\n",
      "15 10 1\n",
      "15 10 2\n",
      "15 10 3\n",
      "15 10 4\n",
      "15 10 5\n",
      "15 11 1\n",
      "15 11 2\n",
      "15 11 3\n",
      "15 11 4\n",
      "15 11 5\n",
      "15 12 1\n",
      "15 12 2\n",
      "15 12 3\n",
      "15 12 4\n",
      "15 12 5\n",
      "15 13 1\n",
      "15 13 2\n",
      "15 13 3\n",
      "15 13 4\n",
      "15 13 5\n",
      "15 14 1\n",
      "15 14 2\n",
      "15 14 3\n",
      "15 14 4\n",
      "15 14 5\n",
      "15 15 1\n",
      "15 15 2\n",
      "15 15 3\n",
      "15 15 4\n",
      "15 15 5\n",
      "C:\\Users\\jmoln\\Documents\\Projects\\NonAnthroHands_User_Study\\data\\PID15\\Reachy_PID15_r_wrist2hand_Motion_gesture_15_5.csv not found, loading alternate data from followup\n",
      "Import data failed for PID 15, gesture 15, demo_num 5\n",
      "16 1 1\n",
      "16 1 2\n",
      "16 1 3\n",
      "16 1 4\n",
      "16 1 5\n",
      "16 2 1\n",
      "16 2 2\n",
      "16 2 3\n",
      "16 2 4\n",
      "16 2 5\n",
      "16 3 1\n",
      "16 3 2\n",
      "16 3 3\n",
      "16 3 4\n",
      "16 3 5\n",
      "16 4 1\n",
      "16 4 2\n",
      "16 4 3\n",
      "16 4 4\n",
      "16 4 5\n",
      "16 5 1\n",
      "16 5 2\n",
      "16 5 3\n",
      "16 5 4\n",
      "16 5 5\n",
      "16 6 1\n",
      "16 6 2\n",
      "16 6 3\n",
      "16 6 4\n",
      "16 6 5\n",
      "16 7 1\n",
      "16 7 2\n",
      "16 7 3\n",
      "16 7 4\n",
      "16 7 5\n",
      "16 8 1\n",
      "16 8 2\n",
      "16 8 3\n",
      "16 8 4\n",
      "16 8 5\n",
      "16 9 1\n",
      "16 9 2\n",
      "16 9 3\n",
      "16 9 4\n",
      "16 9 5\n",
      "16 10 1\n",
      "16 10 2\n",
      "16 10 3\n",
      "16 10 4\n",
      "16 10 5\n",
      "Correcting PID 16, gesture 11\n",
      "16 11 6\n",
      "Correcting PID 16, gesture 11\n",
      "16 11 7\n",
      "Correcting PID 16, gesture 11\n",
      "16 11 8\n",
      "Correcting PID 16, gesture 11\n",
      "16 11 9\n",
      "Correcting PID 16, gesture 11\n",
      "16 11 10\n",
      "Correcting PID 16, gesture 12\n",
      "16 12 7\n",
      "Correcting PID 16, gesture 12\n",
      "16 12 8\n",
      "Correcting PID 16, gesture 12\n",
      "16 12 9\n",
      "Correcting PID 16, gesture 12\n",
      "16 12 10\n",
      "Correcting PID 16, gesture 12\n",
      "16 12 11\n",
      "16 13 1\n",
      "16 13 2\n",
      "16 13 3\n",
      "16 13 4\n",
      "16 13 5\n",
      "16 14 1\n",
      "16 14 2\n",
      "16 14 3\n",
      "16 14 4\n",
      "16 14 5\n",
      "16 15 1\n",
      "16 15 2\n",
      "16 15 3\n",
      "16 15 4\n",
      "16 15 5\n",
      "C:\\Users\\jmoln\\Documents\\Projects\\NonAnthroHands_User_Study\\data\\PID16\\Reachy_PID16_r_wrist2hand_Motion_gesture_15_5.csv not found, loading alternate data from followup\n",
      "Import data failed for PID 16, gesture 15, demo_num 5\n"
     ]
    }
   ],
   "source": [
    "gesture_num=0\n",
    "demo_num = 1\n",
    "\n",
    "robot_name = \"Reachy\"\n",
    "end_eff_name = \"r_wrist2hand_\"\n",
    "\n",
    "# robot_name = \"j2s6s300\"\n",
    "# end_eff_name = \"j2s6s300_end_effector_\"\n",
    "\n",
    "total_end_eff_data = np.array([])\n",
    "total_camera_data  = np.array([])\n",
    "total_rh_data      = np.array([])\n",
    "total_lh_data      = np.array([])\n",
    "total_joint_data   = np.array([])\n",
    "\n",
    "start_index = 1 \n",
    "end_index = -1 \n",
    "# start_index = 77\n",
    "# end_index = -154\n",
    "\n",
    "followup = False\n",
    "\n",
    "if followup:\n",
    "    PIDmax=10\n",
    "    gesturemax = 7\n",
    "else:\n",
    "    PIDmax=17\n",
    "    gesturemax=16\n",
    "\n",
    "gest_target = 4\n",
    "   \n",
    "\n",
    "for PID in range(1,PIDmax):\n",
    "# for PID in range(3,4):\n",
    "    \n",
    "    for gesture_num in range(1,gesturemax):\n",
    "    # for gesture_num in range(gest_target,gest_target+1):\n",
    "        \n",
    "        for demo_num in range(1,6): # Change this to include all demos that exist (and possibly exclude individual ones)\n",
    "            # print(gesture_num, demo_num)\n",
    "            \n",
    "            # LIST OF OVERRIDES:\n",
    "            # These are robots/participants that had erroneous or incomplete data. Two cases exist:\n",
    "            #  1) The user recorded a demo that they later wished to replace with an extra recording. \n",
    "            #     The robot, PID, and gesture to omit/gesture to replace must be specified.\n",
    "            #     The easy way to do this would be to just grab the last five demos for each gesture,\n",
    "            #     but that's not 100% accurate. It was not always the first demo that was the mess-up.\n",
    "            #  2) The robot spazzed out and the user was unable to finish all gestures or motions. \n",
    "            #     I don't think we can account for that here; I think this will affect clustering, workspace \n",
    "            #     coverage, and metrics of user consistency, but that's going to show up later.\n",
    "            \n",
    "            if not followup:\n",
    "                if robot_name[0]=='R':\n",
    "                    if (PID==2 and gesture_num==1):\n",
    "                        print(\"Correcting PID 2, gesture 1\")\n",
    "                        demo_num += 10  #PID2 recorded many extra motions before settling on the last five to show\n",
    "                    elif (PID==9 and gesture_num==4 and demo_num==1):\n",
    "                        print(\"Correcting PID 9, gesture 4, demo 1\")\n",
    "                        demo_num = 6\n",
    "                    elif (PID==16 and gesture_num==11):\n",
    "                        print(\"Correcting PID 16, gesture 11\")\n",
    "                        demo_num += 5\n",
    "                    elif (PID==16 and gesture_num==12):\n",
    "                        print(\"Correcting PID 16, gesture 12\")\n",
    "                        demo_num += 6\n",
    "                elif robot_name[0]=='j':\n",
    "                    if (PID==11 and gesture_num==3 and demo_num==1):\n",
    "                        print(\"Correcting PID 11, gesture 3, demo 1\")\n",
    "                        demo_num = 6\n",
    "                    elif (PID==12 and gesture_num==1 and demo_num==1):\n",
    "                        print(\"Correcting PID 12, gesture 1, demo 1\")\n",
    "                        demo_num = 6\n",
    "                    elif (PID==12 and gesture_num==4):\n",
    "                        print(\"Correcting PID 12, gesture 4\")\n",
    "                        demo_num += 2\n",
    "                    elif (PID==16 and gesture_num==11):\n",
    "                        print(\"Correcting PID 16, gesture 11\")\n",
    "                        demo_num += 1\n",
    "\n",
    "            print(PID, gesture_num, demo_num)\n",
    "            \n",
    "            try:\n",
    "                end_eff_data_temp = load_raw_csv_data(robot_name,end_eff_name, PID, followup, gesture_num, demo_num)\n",
    "                camera_data_temp  = load_raw_csv_data(robot_name,\"Main Camera_\", PID, followup, gesture_num, demo_num)\n",
    "                rh_data_temp      = load_raw_csv_data(robot_name,\"RightHand Controller_\", PID, followup, gesture_num, demo_num)\n",
    "                lh_data_temp      = load_raw_csv_data(robot_name,\"LeftHand Controller_\", PID, followup, gesture_num, demo_num)\n",
    "                joint_data_temp   = load_raw_csv_data(robot_name,\"Joint\", PID, followup, gesture_num, demo_num)\n",
    "    \n",
    "                # I wanted to move this out of the try/catch statement, but then the variable names were out of scope\n",
    "                end_eff_data_temp[:,0] = end_eff_data_temp[:,0]-end_eff_data_temp[0,0]\n",
    "                camera_data_temp[:,0]  = camera_data_temp[:,0]-camera_data_temp[0,0]\n",
    "                rh_data_temp[:,0]      = rh_data_temp[:,0]-rh_data_temp[0,0]\n",
    "                lh_data_temp[:,0]      = lh_data_temp[:,0]-lh_data_temp[0,0]\n",
    "                joint_data_temp[:,0]   = joint_data_temp[:,0]-joint_data_temp[0,0]\n",
    "                \n",
    "                end_eff_data_temp = end_eff_data_temp[start_index:end_index,:]\n",
    "                camera_data_temp  = camera_data_temp[start_index:end_index,:]\n",
    "                rh_data_temp      = rh_data_temp[start_index:end_index,:]\n",
    "                lh_data_temp      = lh_data_temp[start_index:end_index,:]\n",
    "                joint_data_temp   = joint_data_temp[start_index:end_index,:]\n",
    "            except:\n",
    "                error_message = \"Import data failed for PID \"+ str(PID)+\", gesture \"+str(gesture_num)+\", demo_num \"+str(demo_num)\n",
    "                # raise RuntimeError(error_message)\n",
    "                print(error_message)\n",
    "\n",
    "            # More participant-specific exceptions:\n",
    "            if (PID==3 and not followup):\n",
    "                if (gesture_num>=3):\n",
    "                    holding_variable = rh_data_temp\n",
    "                    rh_data_temp = lh_data_temp\n",
    "                    lh_data_temp = holding_variable\n",
    "            # Normalize by participant wingspan\n",
    "            # ...\n",
    "           \n",
    "            try:\n",
    "                if (demo_num==1):\n",
    "                    end_eff_data = end_eff_data_temp\n",
    "                    camera_data  = camera_data_temp\n",
    "                    rh_data      = rh_data_temp\n",
    "                    lh_data      = lh_data_temp\n",
    "                    joint_data   = joint_data_temp\n",
    "                else:   \n",
    "                    end_eff_data = np.vstack((end_eff_data, end_eff_data_temp))\n",
    "                    camera_data  = np.vstack((camera_data, camera_data_temp))\n",
    "                    rh_data      = np.vstack((rh_data, rh_data_temp))\n",
    "                    lh_data      = np.vstack((lh_data, lh_data_temp))\n",
    "                    joint_data  = np.vstack((joint_data, joint_data_temp))\n",
    "            except:\n",
    "                print(\"Stacking data for demo \"+str(demo_num)+\" failed\")\n",
    "    \n",
    "            try:\n",
    "                if followup:\n",
    "                    np.savez('C:\\\\Users\\\\jmoln\\\\Dropbox (GaTech)\\\\Non-Anthropomorphic Hands User Study Data\\\\npz files\\\\data_PID'+str(PID)+\"B_\"+str(robot_name)+\"_gesture_\"+str(gesture_num),\\\n",
    "                             end_eff_data=end_eff_data,rh_data=rh_data,lh_data=lh_data,\\\n",
    "                             camera_data=camera_data,joint_data=joint_data)\n",
    "                else:\n",
    "                    np.savez('C:\\\\Users\\\\jmoln\\\\Dropbox (GaTech)\\\\Non-Anthropomorphic Hands User Study Data\\\\npz files\\\\data_PID'+str(PID)+\"_\"+str(robot_name)+\"_gesture_\"+str(gesture_num),\\\n",
    "                             end_eff_data=end_eff_data,rh_data=rh_data,lh_data=lh_data,\\\n",
    "                             camera_data=camera_data,joint_data=joint_data)\n",
    "   \n",
    "            except: \n",
    "                print(\"Save data failed\")\n",
    "                raise\n",
    "\n",
    "        # try:    \n",
    "        #     if ((PID==1) & (gesture_num==gest_target)):\n",
    "        #         total_end_eff_data = end_eff_data\n",
    "        #         total_camera_data = camera_data\n",
    "        #         total_rh_data     = rh_data\n",
    "        #         total_lh_data     = lh_data\n",
    "        #         total_joint_data  = joint_data\n",
    "        #     else:\n",
    "        #         total_end_eff_data = np.vstack((total_end_eff_data,end_eff_data))\n",
    "        #         total_camera_data  = np.vstack((total_camera_data,camera_data))\n",
    "        #         total_rh_data      = np.vstack((total_rh_data,rh_data))\n",
    "        #         total_lh_data      = np.vstack((total_lh_data,lh_data))\n",
    "        #         total_joint_data   = np.vstack((total_joint_data,joint_data))\n",
    "        # except:\n",
    "        #     print(\"Data was missing from PID\"+str(PID)+\" gesture \"+str(gesture_num))\n",
    "\n",
    "# plot_raw_data(total_end_eff_data, total_rh_data, total_lh_data, total_camera_data, total_joint_data, start_index, end_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "robot_name='j2s6s300'\n",
    "# robot_name='Reachy'\n",
    "participant_ids = (3,3)\n",
    "gesture_num=5\n",
    "followup = False\n",
    "\n",
    "view_participant_robot_gesture(robot_name,participant_ids,gesture_num,followup,centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID = 1\n",
    "followup = False\n",
    "gesture_num = 14\n",
    "end_eff, camera, rh, lh, joint = load_npzs(robot_name, PID, followup, gesture_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pos(gesture_num,\n",
    "             demo_num,\n",
    "             warp_path,\n",
    "             end_eff_pos_aligned,\n",
    "             hand_pos_aligned,\n",
    "             time_URDF_aligned,\n",
    "             time_hand_aligned,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rh-camera)[:,1:7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
